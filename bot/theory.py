import streamlit as st
import socket
import functools
from typing import Optional, Callable
from bot.settings import OPENAI_API_KEY
from langchain_ollama import OllamaLLM
import topics


def log_function_execution(func: Callable) -> Callable:
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π (—É—Å–ø–µ—Ö/–Ω–µ—É–¥–∞—á–∞)"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        func_name = func.__name__
        try:
            result = func(*args, **kwargs)
            print(f"‚úì {func_name} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return result
        except Exception as e:
            print(f"‚úó {func_name} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {e}")
            raise
    return wrapper


class LLMProvider:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ LLM"""
    
    def __init__(self, model_name: str, **kwargs):
        self.model_name = model_name
        self.kwargs = kwargs
        self.client = None
    
    def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        raise NotImplementedError
    
    def invoke(self, prompt: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM"""
        raise NotImplementedError
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        return self.client is not None


class OllamaProvider(LLMProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Ollama"""
    
    def __init__(self, model_name: str = "deepseek-r1:7b", temperature: float = 0.7, **kwargs):
        super().__init__(model_name, temperature=temperature, **kwargs)
        self.temperature = temperature
    
    @log_function_execution
    def _check_server_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(1)
            result = sock.connect_ex(('localhost', 11434))
            sock.close()
            return result == 0
        except Exception:
            return False
    
    def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama –∫–ª–∏–µ–Ω—Ç–∞"""
        if not self._check_server_available():
                return False
            
        try:
            self.client = OllamaLLM(
                model=self.model_name,
                temperature=self.temperature,
                **self.kwargs
            )
            # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
            test_response = self.client.invoke("test")
            if test_response is not None:
                return True
            self.client = None
            return False
        except Exception:
            self.client = None
            return False
    
    def invoke(self, prompt: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama"""
        if not self.client:
            raise RuntimeError("Ollama –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return self.client.invoke(prompt)


class OpenAIProvider(LLMProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è OpenAI"""
    
    def __init__(self, model_name: str = "gpt-4o-mini", api_key: Optional[str] = None, temperature: float = 0.7, **kwargs):
        super().__init__(model_name, temperature=temperature, **kwargs)
        self.api_key = api_key or OPENAI_API_KEY
        self.temperature = temperature
    
    def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞"""
        if not self.api_key:
            return False
        try:
            from openai import OpenAI
            self.client = OpenAI(api_key=self.api_key)
            return True
        except Exception:
            return False
    
    def invoke(self, prompt: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI"""
        if not self.client:
            raise RuntimeError("OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        system_prompt = "–¢—ã –æ–ø—ã—Ç–Ω—ã–π —É—á–∏—Ç–µ–ª—å. –û–±—ä—è—Å–Ω—è–π –º–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ—Å—Ç–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ."
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=self.temperature
        )
        
        if response and response.choices and len(response.choices) > 0:
            return response.choices[0].message.content
        raise RuntimeError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI")


class TheoryManager:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏"""
    
    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
    CURSOR_VARIANTS = ["‚ñå", "‚ñã", "‚ñä", "‚ñâ", "‚ñà", "‚ñê", "‚ñé", "‚ñç"]
    TEXT_REPLACEMENTS = {
        "ollamapull": "ollama pull",
        "ollamalist": "ollama list",
        "deepseek :7b": "deepseek:7b",
        "deepseek-r1 :7b": "deepseek-r1:7b",
        "deepseek:7b–∑–∞–≥—Ä—É–∂–µ–Ω–∞": "deepseek:7b –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
        "deepseek-r1:7b –∑–∞–≥—Ä—É–∂–µ–Ω–∞": "deepseek-r1:7b –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
        "deepseek:7b –∑–∞–≥—Ä—É–∂–µ–Ω–∞:": "deepseek:7b –∑–∞–≥—Ä—É–∂–µ–Ω–∞:",
        "–º–æ–¥–µ–ª—ådeepseek": "–º–æ–¥–µ–ª—å deepseek",
        "–º–æ–¥–µ–ª—å deepseek:7b": "–º–æ–¥–µ–ª—å deepseek:7b",
        "–Ω–µ—É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å": "–Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
        ":ollama pull": ": `ollama pull",
        ":ollama list": ": `ollama list",
        "–∑–∞–≥—Ä—É–∂–µ–Ω–∞:ollama": "–∑–∞–≥—Ä—É–∂–µ–Ω–∞: `ollama",
        "–¥–æ—Å—Ç—É–ø–Ω–∞:ollama": "–¥–æ—Å—Ç—É–ø–Ω–∞: `ollama"
    }
    
    def __init__(self, llm_provider: str = "ollama", model_name: Optional[str] = None, 
                 temperature: float = 0.7, api_key: Optional[str] = None, **llm_kwargs):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TheoryManager
        
        Args:
            llm_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM ("ollama" –∏–ª–∏ "openai")
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "deepseek-r1:7b" –¥–ª—è Ollama –∏–ª–∏ "gpt-4o-mini" –¥–ª—è OpenAI)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.7)
            api_key: API –∫–ª—é—á –¥–ª—è OpenAI (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ settings)
            **llm_kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è LLM
        """
        self.api_key = api_key or OPENAI_API_KEY
        self.SUBJECTS_STRUCTURE = topics.SUBJECTS_STRUCTURE
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ LLM
        if llm_provider.lower() == "openai":
            model_name = model_name or "gpt-4o-mini"
            self.llm_provider = OpenAIProvider(
                model_name=model_name,
                api_key=self.api_key,
                temperature=temperature,
                **llm_kwargs
            )
        else:  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é Ollama
            model_name = model_name or "deepseek-r1:7b"
            self.llm_provider = OllamaProvider(
                model_name=model_name,
                temperature=temperature,
                **llm_kwargs
            )
        
        self.llm_provider.initialize()
        self.init_theory_session()
    
    @log_function_execution
    def init_theory_session(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ –¥–ª—è —Ç–µ–æ—Ä–∏–∏"""
        if 'theory_state' not in st.session_state:
            st.session_state.theory_state = {
                'current_page': 'subjects',
                'selected_subject': None,
                'selected_section': None,
                'selected_topic': None,
                'explanation_text': None
            }
    
    def _clean_text_from_cursor(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç –∫—É—Ä—Å–æ—Ä–∞ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"""
        if not text:
            return ""
        
        cleaned = str(text)
        # –£–±–∏—Ä–∞–µ–º –∫—É—Ä—Å–æ—Ä—ã
        for cursor in self.CURSOR_VARIANTS:
            cleaned = cleaned.replace(cursor, "")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã
        for old, new in self.TEXT_REPLACEMENTS.items():
            cleaned = cleaned.replace(old, new)
        
        return cleaned.strip()
    
    def _save_explanation_text(self, text: Optional[str]) -> Optional[str]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å –æ—á–∏—Å—Ç–∫–æ–π –æ—Ç –∫—É—Ä—Å–æ—Ä–∞"""
        if not text:
            st.session_state.theory_state['explanation_text'] = None
            return None
        
        cleaned_text = self._clean_text_from_cursor(text)
        st.session_state.theory_state['explanation_text'] = cleaned_text
        return cleaned_text
    
    @log_function_execution
    def show_theory_interface(self):
        """–ì–ª–∞–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Ç–µ–æ—Ä–∏–∏"""
        self.init_theory_session()
        
        st.header("üìö –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã")
        self.show_navigation()
        
        page = st.session_state.theory_state['current_page']
        if page == 'subjects':
            self.show_subjects()
        elif page == 'sections':
            self.show_sections()
        elif page == 'topics':
            self.show_topics()
        elif page == 'explanation':
            self.show_explanation()
    
    def show_navigation(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫–Ω–æ–ø–∫–∏"""
        state = st.session_state.theory_state
        
        breadcrumbs = []
        if state['current_page'] != 'subjects':
            breadcrumbs.append("–ü—Ä–µ–¥–º–µ—Ç—ã")
        if state['selected_subject'] and state['current_page'] not in ['subjects', 'sections']:
            breadcrumbs.append(state['selected_subject'])
        if state['selected_section'] and state['current_page'] not in ['subjects', 'sections', 'topics']:
            breadcrumbs.append(state['selected_section'])
        if state['selected_topic']:
            breadcrumbs.append(state['selected_topic'])
        
        if breadcrumbs:
            st.markdown(" ‚Üí ".join(breadcrumbs))
            st.markdown("---")
        
        if state['current_page'] != 'subjects':
            if st.button("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", key="theory_back_button"):
                self.navigate_back()
                st.rerun()
    
    def navigate_back(self):
        """–ù–∞–≤–∏–≥–∞—Ü–∏—è –Ω–∞–∑–∞–¥"""
        state = st.session_state.theory_state
        
        if state['current_page'] == 'explanation':
            state['current_page'] = 'topics'
            state['selected_topic'] = None
            state['explanation_text'] = None
        elif state['current_page'] == 'topics':
            state['current_page'] = 'sections'
            state['selected_section'] = None
        elif state['current_page'] == 'sections':
            state['current_page'] = 'subjects'
            state['selected_subject'] = None
    
    def show_subjects(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤"""
        st.subheader("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ–¥–º–µ—Ç:")
        
        subjects = list(self.SUBJECTS_STRUCTURE.keys())
        
        for i in range(0, len(subjects), 3):
            cols = st.columns(3)
            for j in range(3):
                if i + j < len(subjects):
                    subject = subjects[i + j]
                    with cols[j]:
                        icon = self.SUBJECTS_STRUCTURE[subject]["icon"]
                        if st.button(f"{icon} {subject}", key=f"subject_{subject}", use_container_width=True):
                            state = st.session_state.theory_state
                            state['selected_subject'] = subject
                            state['current_page'] = 'sections'
                            state['selected_section'] = None
                            state['selected_topic'] = None
                            state['explanation_text'] = None
                            st.rerun()
    
    def show_sections(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞–∑–¥–µ–ª—ã –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞"""
        state = st.session_state.theory_state
        subject = state['selected_subject']
        
        if not subject:
            state['current_page'] = 'subjects'
            st.rerun()
            return
        
        icon = self.SUBJECTS_STRUCTURE[subject]["icon"]
        st.subheader(f"{icon} {subject}")
        st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª:")
        
        sections = self.SUBJECTS_STRUCTURE[subject]["sections"]
        
        for section_name in sections.keys():
            if st.button(f"üìñ {section_name}", key=f"section_{section_name}", use_container_width=True):
                state['selected_section'] = section_name
                state['current_page'] = 'topics'
                state['selected_topic'] = None
                state['explanation_text'] = None
                st.rerun()
    
    def show_topics(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–º—ã –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞"""
        state = st.session_state.theory_state
        subject = state['selected_subject']
        section = state['selected_section']
        
        if not subject or not section:
            state['current_page'] = 'subjects'
            st.rerun()
            return
        
        icon = self.SUBJECTS_STRUCTURE[subject]["icon"]
        st.subheader(f"{icon} {subject} ‚Üí {section}")
        st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è:")
        
        topics_list = self.SUBJECTS_STRUCTURE[subject]["sections"][section]["topics"]
        
        for topic in topics_list:
            if st.button(f"üéØ {topic}", key=f"topic_{topic}", use_container_width=True):
                state['selected_topic'] = topic
                state['current_page'] = 'explanation'
                state['explanation_text'] = None
                st.rerun()
            
    @log_function_execution
    def show_explanation(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Ç–µ–º—ã"""
        state = st.session_state.theory_state
        subject = state['selected_subject']
        section = state['selected_section']
        topic = state['selected_topic']
        
        if not all([subject, section, topic]):
            state['current_page'] = 'subjects'
            st.rerun()
            return
        
        icon = self.SUBJECTS_STRUCTURE[subject]["icon"]
        st.subheader(f"{icon} {subject} ‚Üí {section} ‚Üí {topic}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –ª–∏ —Ç–µ–º–∞
        current_topic_key = f"{subject}_{section}_{topic}"
        last_topic_key = state.get('last_topic_key')
        if current_topic_key != last_topic_key:
            state['explanation_displayed'] = False
            state['last_topic_key'] = current_topic_key
        
        explanation_text = state.get('explanation_text')
        if explanation_text:
            explanation_text = self._clean_text_from_cursor(explanation_text)
            self._save_explanation_text(explanation_text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
        is_error_template = explanation_text and any(
            indicator in explanation_text for indicator in [
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
                "–Ω–µ—É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
                "–Ω–µ —É–¥–∞–ª–æ—Å—å—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
                "–°–µ—Ä–≤–µ—Ä Ollama –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –±—ã–ª–∞ –æ—à–∏–±–∫–∞",
                "–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:",
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å"
            ]
        )
        
        if is_error_template:
            state['explanation_text'] = None
            explanation_text = None
        
        if not explanation_text:
            with st.spinner("üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ..."):
                try:
                    full_text = self.get_topic_explanation(subject, section, topic, regenerate=False)
                    full_text = self._clean_text_from_cursor(full_text)
                    
                    if full_text and len(full_text) > 50:
                        is_final_error = (
                            f"## {topic}" in full_text and
                            "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å" in full_text and
                            "**–ü—Ä–µ–¥–º–µ—Ç:**" in full_text
                        )
                        
                        if is_final_error or len(full_text) > 200:
                            explanation_text = self._save_explanation_text(full_text)
                        else:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—à–∏–±–∫–∏
                            full_text_lower = full_text.lower()[:100]
                            explicit_errors = [
                                "–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
                                "–Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
                                "–æ–ª–ª–∞–º–∞ —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                                "—á—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:",
                                "—É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å"
                            ]
                            
                            is_explicit_error = any(err in full_text_lower for err in explicit_errors)
                            is_command = full_text.strip().startswith(("ollama", "Ollama"))
                            
                            if is_explicit_error or is_command:
                                local_explanation = self._get_local_explanation(subject, section, topic)
                                if local_explanation:
                                    explanation_text = self._save_explanation_text(local_explanation)
                                else:
                                    explanation_text = self._get_error_message(subject, section, topic)
                                    explanation_text = self._clean_text_from_cursor(explanation_text)
                                    self._save_explanation_text(explanation_text)
                            else:
                                explanation_text = self._save_explanation_text(full_text)
                    else:
                        raise Exception("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")
                except Exception as e:
                    explanation_text = self._get_error_message(subject, section, topic)
                    explanation_text = self._clean_text_from_cursor(explanation_text)
                    self._save_explanation_text(explanation_text)
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        if explanation_text:
            clean_text = self._clean_text_from_cursor(explanation_text)
            if clean_text:
                explanation_container = st.empty()
                try:
                    explanation_container.markdown(clean_text)
                except Exception:
                    st.markdown(clean_text)
                
                if clean_text != explanation_text:
                    self._save_explanation_text(clean_text)
        
        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        if st.button("üîÑ –ü–æ–ª—É—á–∏—Ç—å –¥—Ä—É–≥–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ", key="regenerate_explanation_button"):
            state['explanation_text'] = None
            state['explanation_displayed'] = False
            st.rerun()
            
    @log_function_execution
    def get_topic_explanation(self, subject: str, section: str, topic: str, regenerate: bool = False) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç–µ–º—ã –æ—Ç LLM"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        if not regenerate:
            local_explanation = self._get_local_explanation(subject, section, topic, generate_if_missing=False)
            if local_explanation:
                return local_explanation
        
        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        if self.llm_provider.is_available():
            try:
                return self._get_llm_explanation(subject, section, topic)
            except Exception:
                pass
        
        # Fallback –Ω–∞ OpenAI, –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä - Ollama
        if isinstance(self.llm_provider, OllamaProvider) and self.api_key:
            try:
                openai_provider = OpenAIProvider(model_name="gpt-4o-mini", api_key=self.api_key, temperature=0.7)
                if openai_provider.initialize():
                    return self._get_llm_explanation_with_provider(subject, section, topic, openai_provider)
            except Exception:
                pass
        
        # –ü—Ä–æ–±—É–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        local_explanation = self._get_local_explanation(subject, section, topic, generate_if_missing=True)
        if local_explanation:
            return local_explanation
        
        return self._get_error_message(subject, section, topic)
    
    def _get_llm_explanation(self, subject: str, section: str, topic: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        return self._get_llm_explanation_with_provider(subject, section, topic, self.llm_provider)
    
    def _get_llm_explanation_with_provider(self, subject: str, section: str, topic: str, provider: LLMProvider) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        system_prompt = f"""–¢—ã –æ–ø—ã—Ç–Ω—ã–π —É—á–∏—Ç–µ–ª—å {subject.lower()}–∞ —Å 20-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º. 
–¢–µ–±–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ—Å—Ç–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å —Ç–µ–º—É "{topic}" –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "{section}".

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏—é:
1. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç–æ–π –∏ –¥–æ—Å—Ç—É–ø–Ω—ã–π —è–∑—ã–∫
2. –ü—Ä–∏–≤–æ–¥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
3. –û–±—ä—è—Å–Ω—è–π —à–∞–≥ –∑–∞ —à–∞–≥–æ–º
4. –ò—Å–ø–æ–ª—å–∑—É–π –∞–Ω–∞–ª–æ–≥–∏–∏ –∏–∑ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏
5. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –º–∞—Ç–µ—Ä–∏–∞–ª –ª–æ–≥–∏—á–Ω–æ
6. –í—ã–¥–µ–ª—è–π –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
7. –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
8. –û–±—ä–µ–º: 300-500 —Å–ª–æ–≤

–ù–∞—á–Ω–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –∫—Ä–∞—Ç–∫–æ–≥–æ –≤–≤–µ–¥–µ–Ω–∏—è –≤ —Ç–µ–º—É, –∑–∞—Ç–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ —Ä–∞–∑–±–µ—Ä–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è –∏ –∑–∞–≤–µ—Ä—à–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–æ–≤–µ—Ç–∞–º–∏ –∏–ª–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è."""
        
        user_prompt = f"–û–±—ä—è—Å–Ω–∏ —Ç–µ–º—É '{topic}' –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ '{section}' –ø—Ä–µ–¥–º–µ—Ç–∞ '{subject}'"
        full_prompt = f"{system_prompt}\n\n{user_prompt}"
        
        response_text = provider.invoke(full_prompt)
        
        if not response_text or len(response_text.strip()) < 50:
            raise ValueError("–ü—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
        error_indicators = [
            "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
            "–Ω–µ—É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
            "Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
            "ollama serve",
            "ollama pull",
            "–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:",
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å"
        ]
        
        response_lower = response_text.lower()
        if any(indicator.lower() in response_lower for indicator in error_indicators):
            raise ValueError("–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ")
        
        if response_text.strip().startswith(("ollama", "Ollama")):
            raise ValueError("–û—Ç–≤–µ—Ç –ø–æ—Ö–æ–∂ –Ω–∞ –∫–æ–º–∞–Ω–¥—É")
        
        return response_text.strip()
    
    def _get_local_explanation(self, subject: str, section: str, topic: str, generate_if_missing: bool = True) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç–µ–º—ã"""
        try:
            from pathlib import Path
            
            # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É
            translit_map = {
                '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'e',
                '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'i', '–∫': 'k', '–ª': 'l', '–º': 'm',
                '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
                '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'shch',
                '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya'
            }
            
            topic_lower = topic.lower()
            topic_filename = ''.join(
                translit_map.get(char, char) if char.isalpha() else '_' if char == ' ' else ''
                for char in topic_lower
                if char.isalnum() or char == '_' or char == ' '
            )
            
            explanations_dir = Path(__file__).parent / "explanations"
            explanations_dir.mkdir(exist_ok=True)
            explanation_file = explanations_dir / f"{topic_filename}.txt"
            
            # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —á–∏—Ç–∞–µ–º –µ–≥–æ
            if explanation_file.exists():
                with open(explanation_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    content = content.replace('{topic}', topic)
                    content = content.replace('{subject}', subject)
                    content = content.replace('{section}', section)
                    return self._clean_text_from_cursor(content)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if generate_if_missing and isinstance(self.llm_provider, OllamaProvider):
                if self.llm_provider.is_available():
                    try:
                        response_text = self._get_llm_explanation(subject, section, topic)
                        if response_text and len(response_text.strip()) > 50:
                            content = self._clean_text_from_cursor(response_text.strip())
                            with open(explanation_file, 'w', encoding='utf-8') as f:
                                f.write(content)
                            return content
                    except Exception:
                        pass
            
            return None
        except Exception:
            return None
    
    def _get_error_message(self, subject: str, section: str, topic: str) -> str:
        """–°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –∫–æ–≥–¥–∞ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"""
        local_explanation = self._get_local_explanation(subject, section, topic, generate_if_missing=False)
        if local_explanation:
            return self._clean_text_from_cursor(local_explanation)
        
        ollama_available = isinstance(self.llm_provider, OllamaProvider) and self.llm_provider._check_server_available()
        has_openai_key = bool(self.api_key)
        model_name = self.llm_provider.model_name
        
        if not ollama_available:
            error_msg = f"""
## {topic}

**–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —ç—Ç–æ–π —Ç–µ–º—ã.**

**Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!**

**–ß—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å {model_name}, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**

1. **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:**
   - –°–∫–∞—á–∞–π—Ç–µ —Å https://ollama.ai
   - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–∞ –≤–∞—à –∫–æ–º–ø—å—é—Ç–µ—Ä

2. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama —Å–µ—Ä–≤–µ—Ä:**
   - –û—Ç–∫—Ä–æ–π—Ç–µ –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É (—Ç–µ—Ä–º–∏–Ω–∞–ª)
   - –í—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É: `ollama serve`
   - –°–µ—Ä–≤–µ—Ä –¥–æ–ª–∂–µ–Ω –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è –Ω–∞ –ø–æ—Ä—Ç—É 11434

3. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å {model_name}:**
   - –í –¥—Ä—É–≥–æ–º –æ–∫–Ω–µ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: `ollama pull {model_name}`
   - –î–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏

4. **–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –æ–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É** –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:**
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±–ª–∞—á–Ω–æ–π –º–æ–¥–µ–ª–∏
- –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —É—á–∏—Ç–µ–ª—é –∑–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É—á–µ–±–Ω–∏–∫–∏ –∏ –æ–Ω–ª–∞–π–Ω-—Ä–µ—Å—É—Ä—Å—ã

**–ü—Ä–µ–¥–º–µ—Ç:** {subject}  
**–†–∞–∑–¥–µ–ª:** {section}  
**–¢–µ–º–∞:** {topic}

–≠—Ç–∞ —Ç–µ–º–∞ –≤–∞–∂–Ω–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏–∑—É—á–∏—Ç—å –µ—ë –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ.
"""
        else:
            if has_openai_key:
                error_msg = f"""## {topic}

**–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —ç—Ç–æ–π —Ç–µ–º—ã.**

**Ollama —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. OpenAI —Ç–∞–∫–∂–µ –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ.**

**–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**

1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞: `ollama pull {model_name}`
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞: `ollama list`
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É (–¥–ª—è OpenAI)
4. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —É—á–∏—Ç–µ–ª—é –∑–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É—á–µ–±–Ω–∏–∫–∏ –∏ –æ–Ω–ª–∞–π–Ω-—Ä–µ—Å—É—Ä—Å—ã

**–ü—Ä–µ–¥–º–µ—Ç:** {subject}  
**–†–∞–∑–¥–µ–ª:** {section}  
**–¢–µ–º–∞:** {topic}

–≠—Ç–∞ —Ç–µ–º–∞ –≤–∞–∂–Ω–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏–∑—É—á–∏—Ç—å –µ—ë –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ.
"""
            else:
                error_msg = f"""## {topic}

**–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —ç—Ç–æ–π —Ç–µ–º—ã.**

**Ollama —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.**

**–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**

1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞: `ollama pull {model_name}`
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞: `ollama list`
3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±–ª–∞—á–Ω–æ–π –º–æ–¥–µ–ª–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
4. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —É—á–∏—Ç–µ–ª—é –∑–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É—á–µ–±–Ω–∏–∫–∏ –∏ –æ–Ω–ª–∞–π–Ω-—Ä–µ—Å—É—Ä—Å—ã

**–ü—Ä–µ–¥–º–µ—Ç:** {subject}  
**–†–∞–∑–¥–µ–ª:** {section}  
**–¢–µ–º–∞:** {topic}

–≠—Ç–∞ —Ç–µ–º–∞ –≤–∞–∂–Ω–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏–∑—É—á–∏—Ç—å –µ—ë –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ.
"""
        
        return self._clean_text_from_cursor(error_msg.strip())


# –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ç–µ–æ—Ä–∏–∏
# –î–ª—è —Ç–µ—Å—Ç–æ–≤: theory_manager = TheoryManager(llm_provider="ollama", model_name="deepseek-r1:7b", temperature=0.7)
# –î–ª—è —Ä–µ–ª–∏–∑–∞: theory_manager = TheoryManager(llm_provider="openai", model_name="gpt-4o-mini", temperature=0.7)
theory_manager = TheoryManager()
